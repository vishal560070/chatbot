{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "G8_BlA98AXLR",
    "outputId": "f66f6099-2919-4388-d171-43eb281590f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Activation, GlobalMaxPooling1D, Embedding\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BE_Q7_wEAsql"
   },
   "outputs": [],
   "source": [
    "#get data\n",
    "URL_Tr = 'https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv'\n",
    "\n",
    "# Load test data\n",
    "train = pd.read_csv(URL_Tr, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "_Llg6frVA3d8",
    "outputId": "6558bfbb-423e-4dad-8b4d-bf9ddf4711c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  ...  Sentiment\n",
       "0         1  ...          1\n",
       "1         2  ...          2\n",
       "2         3  ...          2\n",
       "3         4  ...          2\n",
       "4         5  ...          2\n",
       "5         6  ...          2\n",
       "6         7  ...          2\n",
       "7         8  ...          2\n",
       "8         9  ...          2\n",
       "9        10  ...          2\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the data\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "NUHiOObTBFN0",
    "outputId": "aa6a2130-ad3f-4627-c294-3ee4b2a4d35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4)\n",
      "False\n",
      "8529\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions\n",
    "print(train.shape)\n",
    "\n",
    "# Null entry checking\n",
    "print(train.isnull().values.any())\n",
    "\n",
    "# Number of unique sentences in the training / testing dataset\n",
    "print(len(train.groupby('SentenceId').nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "imUSl2iKBwT9",
    "outputId": "6d78b140-8c5b-44a0-a71a-813c0981d298"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "      <td>Somewhat Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>167</td>\n",
       "      <td>6</td>\n",
       "      <td>A comedy-drama of nearly epic proportions root...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>7</td>\n",
       "      <td>Narratively , Trouble Every Day is a plodding ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214</td>\n",
       "      <td>8</td>\n",
       "      <td>The Importance of Being Earnest , so thick wit...</td>\n",
       "      <td>3</td>\n",
       "      <td>Somewhat Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>9</td>\n",
       "      <td>But it does n't leave you with much .</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>10</td>\n",
       "      <td>You could hate it for the same reason .</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PhraseId  SentenceId  ... Sentiment    sentiment_label\n",
       "0           1           1  ...         1  Somewhat Negative\n",
       "63         64           2  ...         4           Positive\n",
       "81         82           3  ...         1  Somewhat Negative\n",
       "116       117           4  ...         3  Somewhat Positive\n",
       "156       157           5  ...         1  Somewhat Negative\n",
       "166       167           6  ...         4           Positive\n",
       "198       199           7  ...         1  Somewhat Negative\n",
       "213       214           8  ...         3  Somewhat Positive\n",
       "247       248           9  ...         1  Somewhat Negative\n",
       "259       260          10  ...         1  Somewhat Negative\n",
       "\n",
       "[10 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create df of full sentences\n",
    "fullSent = train.loc[train.groupby('SentenceId')['PhraseId'].idxmin()]\n",
    "\n",
    "# Change sentiment to increase readability\n",
    "fullSent['sentiment_label'] = ''\n",
    "Sentiment_label = ['Negative', 'Somewhat Negative',\n",
    "                   'Neutral', 'Somewhat Positive', 'Positive']\n",
    "for sent, label in enumerate(Sentiment_label):\n",
    "  fullSent.loc[train.Sentiment == sent, 'sentiment_label'] = label\n",
    "  \n",
    "fullSent.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "6nh7v4FTSgmr",
    "outputId": "c941ec7f-e348-4d68-e0f7-f4df7c596729"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "      <td>Somewhat Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>167</td>\n",
       "      <td>6</td>\n",
       "      <td>A comedy-drama of nearly epic proportions root...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>7</td>\n",
       "      <td>Narratively , Trouble Every Day is a plodding ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214</td>\n",
       "      <td>8</td>\n",
       "      <td>The Importance of Being Earnest , so thick wit...</td>\n",
       "      <td>3</td>\n",
       "      <td>Somewhat Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>9</td>\n",
       "      <td>But it does n't leave you with much .</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>10</td>\n",
       "      <td>You could hate it for the same reason .</td>\n",
       "      <td>1</td>\n",
       "      <td>Somewhat Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PhraseId  SentenceId  ... Sentiment    sentiment_label\n",
       "0           1           1  ...         1  Somewhat Negative\n",
       "63         64           2  ...         4           Positive\n",
       "81         82           3  ...         1  Somewhat Negative\n",
       "116       117           4  ...         3  Somewhat Positive\n",
       "156       157           5  ...         1  Somewhat Negative\n",
       "166       167           6  ...         4           Positive\n",
       "198       199           7  ...         1  Somewhat Negative\n",
       "213       214           8  ...         3  Somewhat Positive\n",
       "247       248           9  ...         1  Somewhat Negative\n",
       "259       260          10  ...         1  Somewhat Negative\n",
       "\n",
       "[10 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullSent.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-4jYfw3VNJS"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "englishStemmer=SnowballStemmer(\"english\")\n",
    "porter = PorterStemmer()\n",
    "lancaster=LancasterStemmer()\n",
    "\n",
    "\n",
    "def stemSentence(sentence, stemmer):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(stemmer.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "def cleanText(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub(r'[^\\w\\s]','',text)\n",
    "  text=text.replace('\\n',' ')\n",
    "  text = re.sub(r'[0-9]+', '', text)\n",
    "  text=text.strip()\n",
    "  text = stemSentence(text, lancaster)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sI8rjwh5YYaa",
    "outputId": "ea95e6e2-7e4b-45b6-82e7-aae17c308882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 32.03034687042236 seconds ---\n",
      "--- 3.269472599029541 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train['CleanPhrase']=train['Phrase'].apply(cleanText)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "fullSent['CleanPhrase']=fullSent['Phrase'].apply(cleanText)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "1fN8gSydCHrv",
    "outputId": "4c8d5743-6f51-4913-e057-0a8dc1ec6bc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.5, max_features=None, min_df=5,\n",
       "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "                strip_accents='unicode', token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize step\n",
    "BoW_vectorizer = CountVectorizer(strip_accents='unicode',\n",
    "                                 stop_words=None,\n",
    "                                 ngram_range=(1,3),\n",
    "                                 analyzer='word',\n",
    "                                 min_df=5,\n",
    "                                 max_df=0.5)\n",
    "\n",
    "#BoW_vectorizer.fit(list(fullSent['Phrase']))\n",
    "#BoW_vectorizer.fit(list(train['Phrase']))\n",
    "BoW_vectorizer.fit(list(train['CleanPhrase']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "lCuHr-7TCMc_",
    "outputId": "f9013b27-96a3-4c7e-d22c-ca5c52c82923"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=0.5, max_features=None,\n",
       "                min_df=5, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents='unicode',\n",
       "                sublinear_tf=True, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5,\n",
    "                                   max_df=0.5,\n",
    "                                   analyzer='word',\n",
    "                                   strip_accents='unicode',\n",
    "                                   ngram_range=(1,3),\n",
    "                                   sublinear_tf=True,\n",
    "                                   smooth_idf=True,\n",
    "                                   use_idf=True,\n",
    "                                   stop_words=None)\n",
    "\n",
    "#tfidf_vectorizer.fit(list(fullSent['Phrase']))\n",
    "#tfidf_vectorizer.fit(list(train['Phrase']))\n",
    "tfidf_vectorizer.fit(list(train['CleanPhrase']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "11Ck774wCOme",
    "outputId": "d5aa0526-8163-48a9-a573-cae58bcdbf38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124848,), (124848,), (31212,), (31212,))"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build train and test datasets\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(fullSent['Phrase'],\n",
    "#                                                    fullSent['Sentiment'],\n",
    "#                                                    test_size=0.2,\n",
    "#                                                    random_state=4)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train['CleanPhrase'],\n",
    "                                                    train['Sentiment'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=4)\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5rhnZs8zySf"
   },
   "outputs": [],
   "source": [
    "# BoW\n",
    "train_bow = BoW_vectorizer.transform(X_train)\n",
    "test_bow = BoW_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Q9X-Si4AxRU"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TFIDF\n",
    "train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IZRWJf9pDV5K",
    "outputId": "865fbfcf-96f0-41dc-d54e-41069012d034"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<124848x258673 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2604467 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aeAXfLYHEdJr"
   },
   "outputs": [],
   "source": [
    "bow_feature_vec = pd.DataFrame(test_bow.toarray(), columns=BoW_vectorizer.get_feature_names())\n",
    "bow_feature_vec.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMaXndcEDYWg"
   },
   "outputs": [],
   "source": [
    "# Helper function to train and predict\n",
    "def train_model_predict(classifier, train_features, train_labels, test_features):\n",
    "  classifier.fit(train_features, train_labels)\n",
    "  predictions = classifier.predict(test_features)\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MfIXcSojEC1K"
   },
   "outputs": [],
   "source": [
    "# Naive bayes model\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "MNB_TFIDF_y_ = train_model_predict(MNB, train_tfidf, Y_train, test_tfidf)\n",
    "MNB_BoW_y_ = train_model_predict(MNB, train_bow, Y_train, test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "gAWRdQtcEE5y",
    "outputId": "6d85f7b7-4a7c-42bf-bfb3-1e94f22a3a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for LR TFIDF:\n",
      "Accuracy: 0.6332\n",
      "Precision: 0.6224\n",
      "Recall: 0.6332\n",
      "F1 Score: 0.5978\n",
      "\n",
      "Evaluation for LR BoW:\n",
      "Accuracy: 0.6597\n",
      "Precision: 0.6448\n",
      "Recall: 0.6597\n",
      "F1 Score: 0.6441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "LR = LogisticRegression(solver='liblinear',\n",
    "                        multi_class='ovr')\n",
    "\n",
    "LR_TFIDF_y_ = train_model_predict(LR, train_tfidf, Y_train, test_tfidf)\n",
    "LR_BoW_y_ = train_model_predict(LR, train_bow, Y_train, test_bow)\n",
    "\n",
    "\n",
    "print(\"Evaluation for LR TFIDF:\")\n",
    "get_metrics(Y_test, LR_TFIDF_y_, test_tfidf)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Evaluation for LR BoW:\")\n",
    "get_metrics(Y_test, LR_BoW_y_, test_bow)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qx7EftZEHhC"
   },
   "outputs": [],
   "source": [
    "# Performance evaluation\n",
    "# See 'Tensorflow Precision'\n",
    "def get_metrics(true_labels, predicted_labels, feature):\n",
    "  #print(feature)\n",
    "  print('Accuracy:', np.round(metrics.accuracy_score(true_labels, predicted_labels), 4))\n",
    "  print('Precision:', np.round(metrics.precision_score(true_labels, predicted_labels, average='weighted'), 4))\n",
    "  print('Recall:', np.round(metrics.recall_score(true_labels, predicted_labels, average='weighted'), 4))\n",
    "  print('F1 Score:', np.round(metrics.f1_score(true_labels, predicted_labels, average='weighted'), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "id": "873IJt1aEJK6",
    "outputId": "2f41d598-2e36-4ae9-b3b6-1736fd9ba430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for MNB TFIDF:\n",
      "Accuracy: 0.6231\n",
      "Precision: 0.6163\n",
      "Recall: 0.6231\n",
      "F1 Score: 0.5819\n",
      "\n",
      "Evaluation for MNB BoW:\n",
      "Accuracy: 0.5704\n",
      "Precision: 0.5946\n",
      "Recall: 0.5704\n",
      "F1 Score: 0.579\n",
      "\n",
      "Evaluation for LR TFIDF:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7dca7124e98c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation for LR TFIDF:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR_TFIDF_y_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LR_TFIDF_y_' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate each model\n",
    "print(\"Evaluation for MNB TFIDF:\")\n",
    "get_metrics(Y_test, MNB_TFIDF_y_, test_tfidf)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Evaluation for MNB BoW:\")\n",
    "get_metrics(Y_test, MNB_BoW_y_, test_bow)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wA7HQmHERRi"
   },
   "outputs": [],
   "source": [
    "train_tfidf_mat = train_tfidf.toarray()\n",
    "\n",
    "print(type(train_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3KTaDQ7La3_7"
   },
   "outputs": [],
   "source": [
    "train_tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v466R2VUapKj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtDwvhFxE6PU"
   },
   "outputs": [],
   "source": [
    "max_features = train_tfidf.shape[1]\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "\n",
    "\n",
    "# Simple CNN model\n",
    "# Can be any size you want but limited to 100 epochs\n",
    "# Random seed must be 4\n",
    "# Won't work at the moment, need all of the imports\n",
    "def baseline_cnn_model(fea_matrix, n_class, mode, compiler):\n",
    "  model = Sequential()\n",
    "  #model.add(Embedding(max_features,\n",
    "  #                  embedding_dims,\n",
    "  #                  input_length=maxlen))\n",
    "  model.add(Reshape((fea_matrix.shape[1],1), input_shape=(fea_matrix.shape[1],)))\n",
    "  model.add(Conv1D(filters=32, kernel_size=10, activation='relu'))\n",
    "  #print(model_m.summary())\n",
    "  #model.add(Conv1D(filters=64, kernal_size=3, activation='relu'))\n",
    "  model.add(MaxPooling1D(pool_size=2))\n",
    "  #model.add(Conv1D(filters=128, kernel_size=10, activation='relu'))\n",
    "  #model.add(MaxPooling1D(pool_size=2))\n",
    "  model.add(Flatten())\n",
    "  model.add(Activation('relu'))\n",
    "  #model.add(Dense(64))\n",
    "  #model.add(Dropout(0.2))\n",
    "  #model.add(Activation('relu'))\n",
    "  model.add(Dense(n_class))\n",
    "  \n",
    "  if n_class == 1 and mode == \"reg\":\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=compiler, loss='mse', metrics=['acc', f1_m, precision_m, recall_m])\n",
    "    #model.compile(optimizer=compiler, loss='mse')\n",
    "  elif n_class == 1 and mode == \"cla\":\n",
    "    model.add(Activation('sigmoid'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=compiler, loss='binary_crossentropy', metrics=['acc',f1_m, precision_m, recall_m])\n",
    "  else:\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(optimizer=compiler, loss='categorical_crossentropy', metrics=['acc',f1_m, precision_m, recall_m])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whVYXETnE-3U"
   },
   "outputs": [],
   "source": [
    "#model hyper params\n",
    "lr = 1e-3\n",
    "batch_size = 32\n",
    "num_epochs = 25\n",
    "decay = 1e-4\n",
    "mode = \"reg\"\n",
    "n_class = 1\n",
    "\n",
    "adm = optimizers.Adam(lr=lr, decay=decay)\n",
    "sgd = optimizers.SGD(lr=lr, nesterov=True, momentum=0.7, decay=decay)\n",
    "nadam = optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fw8lsDtt_6BH"
   },
   "outputs": [],
   "source": [
    "train_bow_rs = train_bow.reshape(train_bow.shape[0],1,train_bow.shape[1],1)\n",
    "test_bow_rs = test_bow.reshape(test_bow.shape[0],1,test_bow.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZ9x0sdm6pGW"
   },
   "outputs": [],
   "source": [
    "#train_bow_rs = train_bow_rs.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Deh-QtykBGLY"
   },
   "outputs": [],
   "source": [
    "#train_bow_rs = train_bow_rs.reshape(train_bow_rs.shape[0], 1, train_bow_rs.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zBlbHwaj6kFC",
    "outputId": "b17495a9-cff6-4682-8c52-49c52d5db93f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6823, 6946)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "f4l7OSRIALQS",
    "outputId": "aa0b16f2-f90f-421e-816e-fa0341ecede4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 09:56:50.078459 140036102117248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0801 09:56:50.081499 140036102117248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0801 09:56:50.094055 140036102117248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0801 09:56:50.128802 140036102117248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0801 09:56:50.154633 140036102117248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7f5c51fdacc0>>\n"
     ]
    }
   ],
   "source": [
    "model = baseline_cnn_model(train_bow_rs, n_class, mode, nadam)\n",
    "print(model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tKuLFn4FlszO",
    "outputId": "95f6d964-934d-4147-caf9-22bc22460cbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1706,)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uDc8xpQHVK59",
    "outputId": "3a2a4149-aada-4c81-9be4-a5855ad51f42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0801 09:57:06.438268 140036102117248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0801 09:57:06.492955 140036102117248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99878 samples, validate on 24970 samples\n",
      "Epoch 1/25\n",
      "99878/99878 [==============================] - 418s 4ms/step - loss: 1.8899 - acc: 0.4208 - f1_m: 0.9559 - precision_m: 32040.0860 - recall_m: 0.9381 - val_loss: 0.5772 - val_acc: 0.5104 - val_f1_m: 0.9761 - val_precision_m: 0.9644 - val_recall_m: 0.9890\n",
      "Epoch 2/25\n",
      "99878/99878 [==============================] - 412s 4ms/step - loss: 0.4333 - acc: 0.5820 - f1_m: 0.9767 - precision_m: 0.9620 - recall_m: 0.9927 - val_loss: 0.4234 - val_acc: 0.5900 - val_f1_m: 0.9766 - val_precision_m: 0.9616 - val_recall_m: 0.9930\n",
      "Epoch 3/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.3410 - acc: 0.6437 - f1_m: 0.9778 - precision_m: 0.9637 - recall_m: 0.9940 - val_loss: 0.3927 - val_acc: 0.6124 - val_f1_m: 0.9772 - val_precision_m: 0.9620 - val_recall_m: 0.9936\n",
      "Epoch 4/25\n",
      "99878/99878 [==============================] - 412s 4ms/step - loss: 0.2904 - acc: 0.6822 - f1_m: 0.9796 - precision_m: 0.9658 - recall_m: 0.9944 - val_loss: 0.3782 - val_acc: 0.6236 - val_f1_m: 0.9775 - val_precision_m: 0.9633 - val_recall_m: 0.9928\n",
      "Epoch 5/25\n",
      "99878/99878 [==============================] - 412s 4ms/step - loss: 0.3728 - acc: 0.7107 - f1_m: 0.9788 - precision_m: 0.9661 - recall_m: 0.9925 - val_loss: 0.3858 - val_acc: 0.6194 - val_f1_m: 0.9768 - val_precision_m: 0.9656 - val_recall_m: 0.9891\n",
      "Epoch 6/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.2266 - acc: 0.7437 - f1_m: 0.9816 - precision_m: 0.9708 - recall_m: 0.9933 - val_loss: 0.3840 - val_acc: 0.6205 - val_f1_m: 0.9769 - val_precision_m: 0.9654 - val_recall_m: 0.9894\n",
      "Epoch 7/25\n",
      "99878/99878 [==============================] - 412s 4ms/step - loss: 0.2216 - acc: 0.7498 - f1_m: 0.9821 - precision_m: 0.9718 - recall_m: 0.9932 - val_loss: 0.3803 - val_acc: 0.6236 - val_f1_m: 0.9769 - val_precision_m: 0.9660 - val_recall_m: 0.9889\n",
      "Epoch 8/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.2121 - acc: 0.7618 - f1_m: 0.9824 - precision_m: 0.9721 - recall_m: 0.9936 - val_loss: 0.3845 - val_acc: 0.6188 - val_f1_m: 0.9770 - val_precision_m: 0.9672 - val_recall_m: 0.9877\n",
      "Epoch 9/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.1993 - acc: 0.7745 - f1_m: 0.9830 - precision_m: 0.9730 - recall_m: 0.9937 - val_loss: 0.3924 - val_acc: 0.6158 - val_f1_m: 0.9766 - val_precision_m: 0.9679 - val_recall_m: 0.9861\n",
      "Epoch 10/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.1928 - acc: 0.7848 - f1_m: 0.9831 - precision_m: 3204.8825 - recall_m: 0.9932 - val_loss: 0.3916 - val_acc: 0.6185 - val_f1_m: 0.9766 - val_precision_m: 0.9682 - val_recall_m: 0.9861\n",
      "Epoch 11/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.1790 - acc: 0.7974 - f1_m: 0.9844 - precision_m: 0.9754 - recall_m: 0.9941 - val_loss: 0.4004 - val_acc: 0.6129 - val_f1_m: 0.9762 - val_precision_m: 0.9694 - val_recall_m: 0.9838\n",
      "Epoch 12/25\n",
      "99878/99878 [==============================] - 412s 4ms/step - loss: 0.1810 - acc: 0.8073 - f1_m: 0.9844 - precision_m: 0.9758 - recall_m: 0.9937 - val_loss: 0.4159 - val_acc: 0.6028 - val_f1_m: 0.9758 - val_precision_m: 0.9709 - val_recall_m: 0.9816\n",
      "Epoch 13/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.1635 - acc: 0.8137 - f1_m: 0.9851 - precision_m: 0.9771 - recall_m: 0.9938 - val_loss: 0.4110 - val_acc: 0.6062 - val_f1_m: 0.9755 - val_precision_m: 0.9698 - val_recall_m: 0.9821\n",
      "Epoch 14/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.1693 - acc: 0.8178 - f1_m: 0.9856 - precision_m: 0.9780 - recall_m: 0.9937 - val_loss: 0.4172 - val_acc: 0.6024 - val_f1_m: 0.9751 - val_precision_m: 0.9715 - val_recall_m: 0.9796\n",
      "Epoch 15/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.1512 - acc: 0.8259 - f1_m: 0.9861 - precision_m: 0.9792 - recall_m: 0.9936 - val_loss: 0.4197 - val_acc: 0.6016 - val_f1_m: 0.9751 - val_precision_m: 0.9712 - val_recall_m: 0.9798\n",
      "Epoch 16/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.1520 - acc: 0.8294 - f1_m: 0.9860 - precision_m: 3204.8878 - recall_m: 0.9935 - val_loss: 0.4209 - val_acc: 0.6034 - val_f1_m: 0.9755 - val_precision_m: 0.9696 - val_recall_m: 0.9823\n",
      "Epoch 17/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.1608 - acc: 0.8322 - f1_m: 0.9859 - precision_m: 0.9785 - recall_m: 0.9939 - val_loss: 0.4240 - val_acc: 0.6018 - val_f1_m: 0.9754 - val_precision_m: 0.9709 - val_recall_m: 0.9808\n",
      "Epoch 18/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.1410 - acc: 0.8381 - f1_m: 0.9871 - precision_m: 0.9804 - recall_m: 0.9942 - val_loss: 0.4310 - val_acc: 0.5974 - val_f1_m: 0.9756 - val_precision_m: 0.9712 - val_recall_m: 0.9809\n",
      "Epoch 19/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.1377 - acc: 0.8414 - f1_m: 0.9870 - precision_m: 0.9807 - recall_m: 0.9938 - val_loss: 0.4287 - val_acc: 0.5983 - val_f1_m: 0.9756 - val_precision_m: 0.9711 - val_recall_m: 0.9809\n",
      "Epoch 20/25\n",
      "99878/99878 [==============================] - 411s 4ms/step - loss: 0.1525 - acc: 0.8449 - f1_m: 0.9872 - precision_m: 0.9816 - recall_m: 0.9935 - val_loss: 0.4354 - val_acc: 0.5968 - val_f1_m: 0.9749 - val_precision_m: 0.9717 - val_recall_m: 0.9790\n",
      "Epoch 21/25\n",
      "84960/99878 [========================>.....] - ETA: 53s - loss: 0.1273 - acc: 0.8510 - f1_m: 0.9879 - precision_m: 0.9821 - recall_m: 0.9941"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-24c3fba4f955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(train_tfidf, Y_train, batch_size=batch_size, epochs= num_epochs, verbose =1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "nKLLG7CwEFyV",
    "outputId": "bdbce076-ebcd-417e-841c-11d9a81915f1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7759714798e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrdDuRmQWfHT"
   },
   "outputs": [],
   "source": [
    "train_bow.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ra97vthMWsUJ"
   },
   "outputs": [],
   "source": [
    "# Performance evaluation\n",
    "# Alt def\n",
    "def recall_m(y_true, y_pred):\n",
    "  true_positives = K.sum(K.round(K.clip(y_true * y_pred,0,1)))\n",
    "  possible_positives = K.sum(K.round(K.clip(y_true,0,1)))\n",
    "  recall = true_positives/(possible_positives + K.epsilon())\n",
    "  return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "  true_positives=K.sum(K.round(K.clip(y_true*y_pred,0,1)))\n",
    "  predicted_positives = K.sum(K.round(K.clip(y_pred,0,1)))\n",
    "  precision= true_positives/(predicted_positives + K.epsilon())\n",
    "  return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "  precision=precision_m(y_true, y_pred)\n",
    "  recall = recall_m(y_true, y_pred)\n",
    "  return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def print_metrics(accuracy, f1_score, precision, recall):\n",
    "  print('SIMPLE CNN MODEL PERFORMANCE')\n",
    "  print('Accuracy:', np.round(accuracy, 4))\n",
    "  print('Precision:', np.round(precision, 4))\n",
    "  print('Recall:', np.round(recall, 4))\n",
    "  print('F1 Score:', np.round(f1_score, 4))\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "qEtQLF-LZrfu",
    "outputId": "a4463176-09f5-4580-eb00-ab08a93fe09e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31212/31212 [==============================] - 65s 2ms/step\n",
      "SIMPLE CNN MODEL PERFORMANCE\n",
      "Accuracy: 0.5888\n",
      "Precision: 0.9714\n",
      "Recall: 0.9818\n",
      "F1 Score: 0.9761\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model.evaluate(test_bow, Y_test)\n",
    "#y_pred = model.predict(test_bow)\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_tfidf, Y_test)\n",
    "print_metrics(accuracy, f1_score, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lNzsQBSr3wL"
   },
   "outputs": [],
   "source": [
    "ylist = list(y_pred[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7xAxgV2eaIzJ"
   },
   "outputs": [],
   "source": [
    "ytest = list(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DDW-l3yIpIsa",
    "outputId": "0bffc5c4-bfb4-43c1-f8d7-1cc100e315bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7084007"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "kvNwtEr6to9v",
    "outputId": "815cbe15-172b-43ec-8022-0f7adb8d0bd3"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-11fc3b673e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-22f3c3db3897>\u001b[0m in \u001b[0;36mrecall_m\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecall_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrue_positives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mpossible_positives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positives\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_positives\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'list'"
     ]
    }
   ],
   "source": [
    "recall = recall_m(ytest, ylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "M9QsqOsWuP7M",
    "outputId": "42860754-b12d-4677-d6f3-d134720ccb97"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-942c3a1df870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mclip\u001b[0;34m(x, min_value, max_value)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0mmax_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m     \u001b[0mmin_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m     \u001b[0mmax_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.dtype' object has no attribute 'base_dtype'"
     ]
    }
   ],
   "source": [
    "K.clip(Y_test,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "ErpEOMius-Yc",
    "outputId": "fe540c2b-98e3-4c30-a2f2-0466c26b93ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for CNN:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-17c129a5ac36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation for CNN:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-4da56f143760>\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(true_labels, predicted_labels, feature)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m#print(feature)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recall:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation for CNN:\")\n",
    "get_metrics(ytest, ylist, test_tfidf)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9WSomwlDpLNZ"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(train_tfidf.shape[1], embedding_dim, input_length=train_tfidf.shape[1]))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBbBfLMk7cNl"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_tfidf, Y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=False,\n",
    "                    validation_split=0.2,\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(train_tfidf, Y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(test_tfidf, Y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4LDHJHi8HNG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Assignment3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
